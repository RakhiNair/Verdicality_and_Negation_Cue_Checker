{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6befffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       negation_count\n",
      "count     1056.000000\n",
      "mean        20.786932\n",
      "std         22.930868\n",
      "min          0.000000\n",
      "25%          5.000000\n",
      "50%         13.500000\n",
      "75%         29.000000\n",
      "max        256.000000\n",
      "{'avoid': 406, 'absence of': 0, 'dishonest': 14, 'involuntarily': 11, 'without': 1870, 'nobody': 37, 'lest': 10, 'no': 4026, 'not': 14222, 'never': 728, 'neither': 263, 'nor': 364, \"can't\": 0, \"won't\": 0, \"don't\": 0, \"didn't\": 0, \"doesn't\": 0, \"isn't\": 0, \"aren't\": 0, \"wasn't\": 0, \"weren't\": 0, \"haven't\": 0, \"hasn't\": 0, \"hadn't\": 0}\n",
      "Most frequent Negation Cue: not\n",
      "Least frequent Negation Cues: ['absence of', \"can't\", \"won't\", \"don't\", \"didn't\", \"doesn't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import os\n",
    "\n",
    "negation_cues = ['avoid','absence of','dishonest','involuntarily','without','nobody','lest','no', 'not', 'never', 'neither', 'nor', \"can't\", \"won't\", \"don't\", \"didn't\", \"doesn't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\"]\n",
    "\n",
    "# load the IBM Debater â€“ Claim Stance Dataset\n",
    "df = pd.read_csv('article_info.csv')\n",
    "\n",
    "negation_cue_dict = {key: 0 for key in negation_cues}\n",
    "\n",
    "\n",
    "def count_negation_cues(path):\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    tokens = word_tokenize(text)\n",
    "    n_count = 0\n",
    "    for token in tokens:\n",
    "        if token.lower() in negation_cues:\n",
    "            cue = token.lower()\n",
    "            if cue in negation_cue_dict.keys():\n",
    "                negation_cue_dict[cue] += 1\n",
    "            n_count += 1\n",
    "    return n_count\n",
    "\n",
    "\n",
    "def get_least_frequent_negation_cues(d):\n",
    "    min_count = min(d.values())\n",
    "    return [k for k, v in d.items() if v == min_count]\n",
    "\n",
    "\n",
    "df['negation_count'] = df['clean_file'].apply(lambda x: count_negation_cues(x))\n",
    "\n",
    "print(df[['negation_count']].describe())\n",
    "\n",
    "print(negation_cue_dict)\n",
    "\n",
    "print(\"Most frequent Negation Cue:\",max(negation_cue_dict , key=negation_cue_dict.get))\n",
    "print(\"Least frequent Negation Cues:\",get_least_frequent_negation_cues(negation_cue_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37818793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        argument_id  negation_count_premise  negation_count_conclusion\n",
      "count  12326.000000            12326.000000               12326.000000\n",
      "mean    6954.345692                0.784845                   0.189680\n",
      "std     4061.683805                1.066830                   0.408085\n",
      "min        0.000000                0.000000                   0.000000\n",
      "25%     3383.250000                0.000000                   0.000000\n",
      "50%     6979.500000                0.000000                   0.000000\n",
      "75%    10410.750000                1.000000                   0.000000\n",
      "max    14114.000000               10.000000                   3.000000\n",
      "{'avoid': 222, 'absence of': 0, 'dishonest': 2, 'involuntarily': 4, 'without': 763, 'nobody': 53, 'lest': 6, 'no': 2250, 'not': 8075, 'never': 389, 'neither': 92, 'nor': 156, \"can't\": 0, \"won't\": 0, \"don't\": 0, \"didn't\": 0, \"doesn't\": 0, \"isn't\": 0, \"aren't\": 0, \"wasn't\": 0, \"weren't\": 0, \"haven't\": 0, \"hasn't\": 0, \"hadn't\": 0}\n",
      "Most frequent Negation Cue: not\n",
      "Least frequent Negation Cues: ['absence of', \"can't\", \"won't\", \"don't\", \"didn't\", \"doesn't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\"]\n"
     ]
    }
   ],
   "source": [
    "# load the Webis-Argument-Framing-19 dataset\n",
    "df = pd.read_csv('Webis-argument-framing.csv')\n",
    "\n",
    "negation_cue_dict = {key: 0 for key in negation_cues}\n",
    "\n",
    "\n",
    "def count_negation_cues(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    n_count = 0\n",
    "    for token in tokens:\n",
    "        if token.lower() in negation_cues:\n",
    "            cue = token.lower()\n",
    "            if cue in negation_cue_dict.keys():\n",
    "                negation_cue_dict[cue] += 1\n",
    "            n_count += 1\n",
    "    return n_count\n",
    "\n",
    "\n",
    "df['negation_count_premise'] = df['premise'].apply(count_negation_cues)\n",
    "\n",
    "df['negation_count_conclusion'] = df['conclusion'].apply(count_negation_cues)\n",
    "\n",
    "\n",
    "print(df[['argument_id', 'negation_count_premise','negation_count_conclusion']].describe())\n",
    "\n",
    "\n",
    "print(negation_cue_dict)\n",
    "\n",
    "print(\"Most frequent Negation Cue:\",max(negation_cue_dict , key=negation_cue_dict.get))\n",
    "print(\"Least frequent Negation Cues:\",get_least_frequent_negation_cues(negation_cue_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e783641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ARGUMENT  negation_count\n",
      "count  1029.000000     1029.000000\n",
      "mean      1.842566        0.919339\n",
      "std       0.794250        1.049507\n",
      "min       1.000000        0.000000\n",
      "25%       1.000000        0.000000\n",
      "50%       2.000000        1.000000\n",
      "75%       2.000000        1.000000\n",
      "max       5.000000        6.000000\n",
      "{'avoid': 17, 'absence of': 0, 'dishonest': 0, 'involuntarily': 0, 'without': 89, 'nobody': 5, 'lest': 0, 'no': 107, 'not': 678, 'never': 40, 'neither': 4, 'nor': 6, \"can't\": 0, \"won't\": 0, \"don't\": 0, \"didn't\": 0, \"doesn't\": 0, \"isn't\": 0, \"aren't\": 0, \"wasn't\": 0, \"weren't\": 0, \"haven't\": 0, \"hasn't\": 0, \"hadn't\": 0}\n",
      "Most frequent Negation Cue: not\n",
      "Least frequent Negation Cues: ['absence of', 'dishonest', 'involuntarily', 'lest', \"can't\", \"won't\", \"don't\", \"didn't\", \"doesn't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\"]\n"
     ]
    }
   ],
   "source": [
    "# load the subset dataset of the collected student essays by Stab and Gurevych\n",
    "df = pd.read_csv('UKP-InsufficientArguments_v1.0/data-tokenized.tsv', sep='\\t', encoding='iso-8859-1')\n",
    "\n",
    "negation_cue_dict = {key: 0 for key in negation_cues}\n",
    "\n",
    "df['negation_count'] = df['TEXT'].apply(count_negation_cues)\n",
    "\n",
    "\n",
    "print(df[['ARGUMENT', 'negation_count']].describe())\n",
    "\n",
    "print(negation_cue_dict)\n",
    "\n",
    "print(\"Most frequent Negation Cue:\",max(negation_cue_dict , key=negation_cue_dict.get))\n",
    "print(\"Least frequent Negation Cues:\",get_least_frequent_negation_cues(negation_cue_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383426f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
